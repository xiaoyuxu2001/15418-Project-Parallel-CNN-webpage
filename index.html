<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>Parallel Deep Neural Network</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Parallel Deep Neural Network</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              Xiaoyu Xu</a>,</span>
            <span class="author-block">
              Qinghan Chen</a></span>
          </div>


          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://docs.google.com/document/d/1pi2YeB6IkAG05BAPqtMgJqTtS88wdQKDPFw-zw42rtg/edit"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Proposal</span>
                </a>
              </span>

              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/xiaoyuxu2001/Parallel_CNN"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://www.kaggle.com/datasets/oddrationale/mnist-in-csv"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>




<section class="section" id="background-section">
    <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
            <h2 class="title is-3" style="color: white;">BACKGROUND</h2>
            <div class="content has-text-justified">
            <p>
              Neural networks often require a substantial amount of computational power for training, making it necessary to employ strategies for parallel computation.
              The two primary ways of parallelizing computation: model and data parallelism. In data parallelism involves partitioning the dataset into smaller batches for processing, while for model parallelism, the architecture of the neural network is divided into several subgraphs.
              Efficient communication across different computing nodes is cruciawwl for the effective execution of parallel deep learning.
              In this project, we implemented sequential and parallel versions of CNN from scratch using numpy and mpi4py.
            </p>
    
            </div>
        </div>
        </div>
</section>
    
<section class="section">
    <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
            <h2 class="title is-3">CHALLENGES</h2>
            <div class="content has-text-justified">
            <p>
                
            </p>
    
            </div>
        </div>
        </div>
</section>

<section class="section">
    <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
            <h2 class="title is-3">GOALS AND DELIVERABLES</h2>
            <div class="content has-text-justified">
            <p>
              We have developed both sequential and parallelized versions of Convolutional Neural Network (CNN) for image classification .
              We constructed the sequential version of the CNN utilizing only numpy to establish a baseline.
              Our approach strategically applies data parallelism to the convolutional layers and tensor model parallelism to the fully connected layers using MPI.
              We implemented matrix multiplication using PyCUDA on a GPU.
              We achieve a 541.87x speedup when running parallelized model on GHC machine with nproc = 8 against the purely sequential one.
            </p>
    
            </div>
        </div>
        </div>
    </section>

<section class="section">
    <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
            <h2 class="title is-3">SCHEDULE</h2>
            <div class="content has-text-justified">
            <p>
                Week 1 (Nov.6 - Nov.12): Finalize project proposal, build webpage, read papers.
            </p>
            <p>
                Week 2 (Nov.13 - Nov.19): Tried to implement parallelized RNN (DRAW: a Recurrent Nerual Network For Image Generation), but found it to have very strong time dependency.
            </p>
            </p>
                Week3 (Nov.20 - Nov.26): Switched to parallel CNN. Implemented sequential version.
            </p>            
            </p>
                Week4 (Nov.27 - Dec.2): Implemented ring reduce and data parallel.
           </p>
            </p>
            Week5 (Nov.2 - Dec.8): Implemented model parallel.
            </p>
          </p>
            Week6 (Nov.9 - Dec.15): Integrate pieces together, doing optimizations, poster and report writeup.
          </p>
            </div>
        </div>
        </div>
    </section>


<section class="section">
    <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
            <h2 class="title is-3">RESOURCES</h2>
            <div class="content has-text-justified">
                <p>
                  These are the papers that we refered to: 
                </p>
                <p>
                  <a href="https://arxiv.org/pdf/1404.5997.pdf">Paper 1</a>: One weird trick for parallelizing convolutional neural networks
                </p>
                <p>
                  These are the code that we used as part of our starter code: 
                </p>
                <p>
                  <a href="https://github.com/vzhou842/cnn-from-scratch">Git repo 1</a>: Sequential starter code reference
                </p>
              </div>
        </div>
        </div>

  </div>
</section>

</body>
</html>